---
changelog:
- 2024-03-17, gpt-4-0125-preview, translated from English
date: 2024-03-17 21:46:35.714889-06:00
description: "\u0E27\u0E34\u0E18\u0E35\u0E01\u0E32\u0E23: \u0E19\u0E35\u0E48\u0E40\
  \u0E1B\u0E47\u0E19\u0E27\u0E34\u0E18\u0E35\u0E17\u0E35\u0E48\u0E23\u0E27\u0E14\u0E40\
  \u0E23\u0E47\u0E27\u0E41\u0E25\u0E30\u0E07\u0E48\u0E32\u0E22\u0E42\u0E14\u0E22\u0E43\
  \u0E0A\u0E49 Fish Shell \u0E01\u0E31\u0E1A\u0E04\u0E33\u0E2A\u0E31\u0E48\u0E07 `curl`\
  \ \u0E43\u0E19\u0E01\u0E32\u0E23\u0E14\u0E32\u0E27\u0E19\u0E4C\u0E42\u0E2B\u0E25\
  \u0E14\u0E2B\u0E19\u0E49\u0E32\u0E40\u0E27\u0E47\u0E1A."
lastmod: '2024-03-17T21:57:56.644187-06:00'
model: gpt-4-0125-preview
summary: "\u0E19\u0E35\u0E48\u0E40\u0E1B\u0E47\u0E19\u0E27\u0E34\u0E18\u0E35\u0E17\
  \u0E35\u0E48\u0E23\u0E27\u0E14\u0E40\u0E23\u0E47\u0E27\u0E41\u0E25\u0E30\u0E07\u0E48\
  \u0E32\u0E22\u0E42\u0E14\u0E22\u0E43\u0E0A\u0E49 Fish Shell \u0E01\u0E31\u0E1A\u0E04\
  \u0E33\u0E2A\u0E31\u0E48\u0E07 `curl` \u0E43\u0E19\u0E01\u0E32\u0E23\u0E14\u0E32\
  \u0E27\u0E19\u0E4C\u0E42\u0E2B\u0E25\u0E14\u0E2B\u0E19\u0E49\u0E32\u0E40\u0E27\u0E47\
  \u0E1A."
title: "\u0E01\u0E32\u0E23\u0E14\u0E32\u0E27\u0E19\u0E4C\u0E42\u0E2B\u0E25\u0E14\u0E2B\
  \u0E19\u0E49\u0E32\u0E40\u0E27\u0E47\u0E1A"
weight: 42
---

## วิธีการ:
นี่เป็นวิธีที่รวดเร็วและง่ายโดยใช้ Fish Shell กับคำสั่ง `curl` ในการดาวน์โหลดหน้าเว็บ:

```fish
curl -O http://example.com/
```

คำสั่งนี้จะดึงเนื้อหาของหน้าเว็บและบันทึกโดยใช้ชื่อไฟล์เดียวกับที่เซิร์ฟเวอร์ (`index.html` สำหรับกรณีส่วนใหญ่)

ตอนนี้, สมมติว่าคุณต้องการบันทึกด้วยชื่ออื่น:

```fish
curl -o my_page.html http://example.com/
```

ต้องการเห็นว่าคุณกำลังดึงอะไรมาบ้าง? นี่คือวิธีแสดงผลลัพธ์ในคอนโซล:

```fish
curl http://example.com/
```

ผลลัพธ์ตัวอย่างอาจมีลักษณะดังนี้:

```
<!doctype html>
<html>
<head>
    <title>Example Domain</title>
...
```

## การทำความเข้าใจลึกซึ้ง
ย้อนกลับไปในวันแรก ๆ การดึงข้อมูลจากเว็บเพจมีมากกว่าเพียงแค่ความมหัศจรรย์ของบรรทัดคำสั่ง เครื่องมืออย่าง `wget` และ `curl` กลายเป็นสิ่งจำเป็น `curl` ที่มีมาตั้งแต่ปี '97 ยังคงอยู่จนถึงปัจจุบันในการส่งข้อมูลโดยใช้รูปแบบ URL

ทำไมถึงเลือก `curl` มากกว่า `wget`? `curl` เป็นดั่งมีดพกสวิสสำหรับการถ่ายโอนข้อมูล, จัดการกับช่วงของโพรโทคอลและรูปแบบข้อมูล ในขณะที่ทั้งสองสามารถดาวน์โหลดหน้าเว็บได้, `curl` ยังสามารถอัปโหลดข้อมูล, และรองรับโพรโทคอลมากขึ้น และบ่อยครั้งที่ถูกใช้เป็นเครื่องมือหลังบ้านโดยซอฟต์แวร์อื่น ๆ

Fish Shell เองไม่มีฟังก์ชั่นดาวน์โหลดเว็บเพจ; มันเป็นเพียงอินเทอร์เฟส แต่เมื่อจับคู่กับ `curl`, คุณจะได้ระบบดึงข้อมูลจากเว็บที่ทั้งมีพลังและง่ายดายด้วยคำสั่งเพียงแค่หนึ่งบรรทัด

บางคนอาจเสนอการใช้เครื่องมือสมัยใหม่เช่น `httpie` หรือการทำงานอัตโนมัติบนเบราว์เซอร์ด้วยเครื่องมืออย่าง Selenium สำหรับงานที่ซับซ้อนมากกว่า เช่น การจัดการกับหน้าที่มีการใช้ Javascript อย่างหนัก อย่างไรก็ตาม, สำหรับการดาวน์โหลดที่รวดเร็วและตรงไปตรงมา, `curl` ยังคงครองความนิยม

## ดูเพิ่มเติม
- เว็บไซต์โปรเจค curl สำหรับรายละเอียดเพิ่มเติม: [https://curl.se/](https://curl.se/)
- สำหรับการดำดิ่งลงไปในการดำเนินการ HTTP ด้วย `curl`, ดูที่ man page: `man curl`
- httpie ซึ่งเป็นตัวเลือกไคลเอนต์ HTTP ที่เป็นมิตรกับผู้ใช้: [https://httpie.org/](https://httpie.org/)
- เอกสารข้อมูล Fish Shell สำหรับการจัดการกับงานที่เกี่ยวข้องกับ shell อื่น ๆ: [https://fishshell.com/docs/current/index.html](https://fishshell.com/docs/current/index.html)
